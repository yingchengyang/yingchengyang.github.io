<!DOCTYPE html>
<html>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PEAC for cross-embodiment unsupervised reinforcement learning.">
  <meta name="keywords" content="Reinforcement Learning, Cross-embodiment, Unsupervised Pre-training">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PEAC: Unsupervised Pre-training for Cross-Embodiment Reinforcement Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="../../static/css/bulma.min.css">
  <link rel="stylesheet" href="../../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="../../static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="../../static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="../../static/css/index.css">
  <link rel="icon" href="../../static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="../../static/js/fontawesome.all.min.js"></script>
  <script src="../../static/js/bulma-carousel.min.js"></script>
  <script src="../../static/js/bulma-slider.min.js"></script>
  <script src="../../static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PEAC: Unsupervised Pre-training for<br> Cross-Embodiment Reinforcement Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"> 
              <!-- <sup>1</sup> -->
              <a href="https://yingchengyang.github.io/">Chengyang Ying</a>,</span>
            <span class="author-block">
              <a href="https://haozhongkai.github.io/">Zhongkai Hao</a>,</span>
            <span class="author-block">
              <a href="https://coderlemon17.github.io/">Xinning Zhou</a>,</span>
            <span class="author-block">
              <a href="https://github.com/xuxuezhou">Xuezhou Xu</a>,</span>
            <span class="author-block">
              <a href="https://www.suhangss.me/">Hang Su</a>,</span>
            <span class="author-block">
              <a href="https://indussky8.github.io/">Xingxing Zhang</a>,</span>
            <span class="author-block">
              <a href="https://ml.cs.tsinghua.edu.cn/~jun/index.shtml">Jun Zhu</a></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Tsinghua University</span>
            <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span style="font-weight: bold;">NeurIPS 2024</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=LyAFfdx8YF"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.14073"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/thu-ml/CEURL"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
    <h2 class="title is-3">Overview</h2>
    <div class="content has-text-justified">
    <p>强化学习里面有很多经典的理论结果，比如策略梯度定理，两个策略的累计期望奖励的差等等，这个blog介绍一个统一的工具来分析这些问题。

    考虑一个MDP $\mathcal{M}=(\mathcal{S},\mathcal{A},\mathcal{P}, \mathcal{R},\gamma,\rho_0)$和策略$\pi$，我们可以定义
    $$
    \begin{equation}
        d_{\mathcal{M}}^{\pi}(s) = (1-\gamma)\sum_{t=0}^{\infty} \gamma^t \mathcal{P}(s_t=s|\pi,\mathcal{M}).
    \end{equation}
    $$
    我们有如下引理<br>

    <b>引理：</b>对于任意$\mathcal{S}$上的函数$f,g$，如果他们满足
    $$
    \begin{equation}
    \label{eq_bell}
        f(s) = g(s) + \gamma\int \pi(a|s)\mathcal{P}(s'|s,a) f(s') dads',
    \end{equation}
    $$
    那么我们有
    $$
    \begin{equation}
    \label{eq_result}
        \mathbb{E}_{s\sim\rho_0} \left[f(s)\right] = \frac{1}{1-\gamma}\mathbb{E}_{s\sim d_{\mathcal{M}}^{\pi}} \left[g(s)\right].
    \end{equation}
    $$
    为了便于阅读，我们先看看这个引理的具体应用，然后再给出这个引理的证明。
   </p>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
    <h2 class="title is-3">Policy Gradient [1]</h2>
    <div class="content has-text-justified">
    <p>我们取$f(s) = \nabla_{\pi} [V_{\pi,\mathcal{M}}(s)]$, 自然地，我们有
      $$
      \begin{equation}
      \begin{split}
          f(s) =& \nabla_{\pi} [V_{\pi,\mathcal{M}}(s)] = \nabla_{\pi} \left[\int \pi(a|s) Q_{\pi,\mathcal{M}}(s) ds\right] \\
          =& \underbrace{\int Q_{\pi,\mathcal{M}}(s) \nabla_{\pi} \pi(a|s) ds}_{\mathrm{defined\ as\ } g(s)}  + \int \pi(a|s) [\nabla_{\pi}  Q_{\pi,\mathcal{M}}(s)] ds \\
          =& g(s) + \int \pi(a|s) \nabla_{\pi} \left[\int \mathcal{R}(s,a) + \gamma \int \mathcal{P}(s'|s,a) V_{\pi,\mathcal{M}}(s') ds' da\right] ds \\
          =& g(s) + \int \pi(a|s)  \left[ \gamma \int \mathcal{P}(s'|s,a) \nabla_{\pi} V_{\pi,\mathcal{M}}(s') ds' da\right] ds \\
          =& g(s) + \gamma \int \pi(a|s)  \mathcal{P}(s'|s,a) \underbrace{\nabla_{\pi} V_{\pi,\mathcal{M}}(s')}_{f(s')} ds' da ds.
      \end{split}
      \end{equation}
      $$
      因此我们就可以得到
      $$
      \begin{equation}
      \begin{split}
          \nabla_{\pi} J_{\mathcal{M}}(\pi) = & \nabla_{\pi} \mathbb{E}_{s\sim\rho_0} [V_{\mathcal{M}, \pi}(s)] =  \mathbb{E}_{s\sim\rho_0} [\nabla_{\pi} V_{\mathcal{M}, \pi}(s)] =  \mathbb{E}_{s\sim\rho_0} [f(s)] \\
          = & \frac{1}{1-\gamma}\mathbb{E}_{s\sim d_{\mathcal{M}}^{\pi}} [g(s)] =\frac{1}{1-\gamma}\mathbb{E}_{s\sim d_{\mathcal{M}}^{\pi}} \int [\nabla_{\pi} \pi(a|s)] Q_{\pi,\mathcal{M}}(s) ds \\
          = & \frac{1}{1-\gamma}\mathbb{E}_{s\sim d_{\mathcal{M}}^{\pi}, a\sim\pi(\cdot|s)} [Q_{\pi,\mathcal{M}}(s) \nabla_{\pi} \log\pi(a|s)],
      \end{split}
      \end{equation}
      $$
      这样我们就证明了策略梯度定理（Policy Gradient）。
   </p>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
    <h2 class="title is-3">Policy Gradient [1]</h2>
    <div class="content has-text-justified">
    <p>一个经常被考虑的问题是不同策略在不同MDP下的累计期望奖励的差，即给定另一个MDP $\mathcal{M}'$和策略$\pi'$，我们考虑$J_{\mathcal{M'}}(\pi') - J_{\mathcal{M}}(\pi)$。

      我们取$f(s) = V_{\pi',\mathcal{M}'}(s) - V_{\pi,\mathcal{M}}(s)$,自然地，我们有
      $$
      \begin{equation}
      \begin{split}
          & f(s) = V_{\pi',\mathcal{M}'}(s) - V_{\pi,\mathcal{M}}(s)\\
          = & V_{\pi',\mathcal{M}'}(s)
          - \int \pi(a|s) \left[\mathcal{R}(s,a) +  \gamma\mathcal{P}(s'|s,a)V_{\pi, \mathcal{M}}(s')\right]dads' \\
          = & \underbrace{V_{\pi',\mathcal{M}'}(s) - \int \pi(a|s) \left[\mathcal{R}(s,a) +  \gamma\mathcal{P}(s'|s,a)V_{\pi', \mathcal{M}'}(s')\right] dads'}_{\mathrm{defined\ as\ } g(s)} \\
          + & \gamma \int \pi(a|s)    \mathcal{P}(s'|s,a)\underbrace{\left[V_{\pi', \mathcal{M}'}(s') - V_{\pi, \mathcal{M}}(s')\right]}_{f(s')} dads'.
      \end{split}
      \end{equation}
      $$
      因此我们可以得到
      $$
      \begin{equation}
      \begin{split}
          & J_{\mathcal{M'}}(\pi') - J_{\mathcal{M}}(\pi) = \mathbb{E}_{s\sim \rho_0} [V_{\pi',\mathcal{M}'}(s) - V_{\pi,\mathcal{M}}(s)] =  \mathbb{E}_{s\sim\rho_0} [f(s)] 
          = \frac{1}{1-\gamma}\mathbb{E}_{s\sim d_{\mathcal{M}}^{\pi}} [g(s)] \\
          % = &\frac{1}{1-\gamma} \int d_{\mathcal{M}}^{\pi}(s) \left[V_{\pi',\mathcal{M}'}(s) - \pi(a|s) \left[\mathcal{R}(s,a) +  \gamma\mathcal{P}(s'|s,a)V_{\pi', \mathcal{M}'}(s')\right]\right]  dsdads'.
      \end{split}
      \end{equation}
      $$
      
      特别的，当$\mathcal{M}'=\mathcal{M}$时，$g(s)$可以简化为：
      $$
      \begin{equation}
      \begin{split}
      \label{eq_same_mdp}
          g(s) = & V_{\pi',\mathcal{M}}(s) - \int \pi(a|s) \left[\mathcal{R}(s,a) +  \gamma\mathcal{P}(s'|s,a)V_{\pi', \mathcal{M}}(s')\right] dads' \\
          = & V_{\pi',\mathcal{M}}(s) - \int \pi(a|s) Q_{\pi', \mathcal{M}}(s,a) da \\
          \overset{(*)}{=} & \int (\pi'(a|s) - \pi(a|s)) Q_{\pi', \mathcal{M}}(s,a) da \\
          = & \int (\pi'(a|s) - \pi(a|s)) Q_{\pi', \mathcal{M}}(s,a) da - \underbrace{\int (\pi'(a|s) - \pi(a|s)) V_{\pi', \mathcal{M}}(s) da}_{=0}  \\
          = & \int (\pi'(a|s) - \pi(a|s)) A_{\pi', \mathcal{M}}(s,a) da   \\
          = & \int (\pi'(a|s) - \pi(a|s)) A_{\pi', \mathcal{M}}(s,a) da - \underbrace{\int \pi'(a|s) A_{\pi', \mathcal{M}}(s,a) da}_{=0} \\
          = & - \int  \pi(a|s) A_{\pi', \mathcal{M}}(s,a) da .
      \end{split}
      \end{equation}
      $$
      因此我们得到
      $$
      \begin{equation}
      \begin{split}
          J_{\mathcal{M}}(\pi') - J_{\mathcal{M}}(\pi) = \frac{-1}{1-\gamma} \int d_{\mathcal{M}}^{\pi}(s) \pi(a|s) A_{\pi', \mathcal{M}}(s,a) dsda.
      \end{split}
      \end{equation}
      $$
      这就是文章~\cite{kakade2002approximately}中的引理6.1以及TRPO中~\cite{schulman2015trust}的式子(2)。
      
      同时，我们也可以基于式子$(*)$证明贪心策略的策略提升（Policy Improvement），我们有
      $$
      \begin{equation}
      \begin{split}
          J_{\mathcal{M}}(\pi') - J_{\mathcal{M}}(\pi) = \frac{1}{1-\gamma} \int d_{\mathcal{M}}^{\pi}(s) (\pi'(a|s) - \pi(a|s)) Q_{\pi', \mathcal{M}}(s,a) ds da,
      \end{split}
      \end{equation}
      $$
      交换一下$\pi$和$\pi'$可以得到
      $$
      \begin{equation}
      \begin{split}
          J_{\mathcal{M}}(\pi) - J_{\mathcal{M}}(\pi') = \frac{1}{1-\gamma} \int d_{\mathcal{M}}^{\pi'}(s) (\pi(a|s) - \pi'(a|s)) Q_{\pi, \mathcal{M}}(s,a) ds da \leq 0,
      \end{split}
      \end{equation}
      $$
      这里最后一个小于等于号是因为$\pi'(s) = \argmax_a Q_{\pi,\mathcal{M}}(s,a)$。
      
      除此之外，我们也可以得到$J_{\mathcal{M}}(\pi') - J_{\mathcal{M}}(\pi)$的一些上界，为了不影响阅读的连贯性，我们把这些内容放到~\ref{sec_upper_bound}小节。
   </p>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{ying2024peac,
      title={PEAC: Unsupervised Pre-training for Cross-Embodiment Reinforcement Learning},
      author={Ying, Chengyang and Hao, Zhongkai and Zhou, Xinning and Xu, Xuezhou and Su, Hang and Zhang, Xingxing and Zhu, Jun},
      journal={arXiv preprint arXiv:2405.14073},
      year={2024}
}</code></pre>
  </div>
</section>

<h1 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h1>
<p>[1] Richard S Sutton, David McAllester, Satinder Singh, and Yishay Mansour. <a href="https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf">&ldquo;Policy gradientmethods for reinforcement learning with function approximation.&ldquo;</a> Advances in neural informationprocessing systems, 12, 1999.</p>



<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is constructed using the source code provided by <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and we are grateful for their template.
            <!-- This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>
          <!-- <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p> -->
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>